{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Respuestas_Tarea_3_CC6402_2019",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCszeuRk0NuH",
        "colab_type": "text"
      },
      "source": [
        "# Tarea 3 Regularización y Generalización <br/> CC6204 Deep Learning, Universidad de Chile  <br/> Hoja de respuestas\n",
        "## Nombre: \n",
        "Fecha de entrega: 1 de octubre de 2019"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QQB7jV7LMEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Este notebook está pensado para correr en CoLaboratory. \n",
        "# Lo único imprescindible por importar es torch \n",
        "import torch\n",
        "\n",
        "# Posiblemenete quieras instalar e importar ipdb para debuggear.\n",
        "# Si es así, descomenta lo siguiente\n",
        "# !pip install -q ipdb\n",
        "# import ipdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9AZ2AGhYIW-",
        "colab_type": "text"
      },
      "source": [
        "# Parte 1: Regularización por norma $L_2$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF4MAAHvYwP-",
        "colab_type": "text"
      },
      "source": [
        "## \"Penalización de norma L2 en la pérdida\" + \"Regularización por dropout\" (1a + Parte 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP0ZWhagYKgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Acá deberías modificar la implementacion de tu red FFNN \n",
        "# para que reciba los parámetro l2_par y l_keep_prob\n",
        "# Puedes incluir todo el código de las Tarea 1 y 2 que quieras.\n",
        "class FFNN(torch.nn.Module):\n",
        "  def __init__(self, F, l_h, l_a, C, l_keep_prob, l2_par=None):\n",
        "    super(FFNN, self).__init__()\n",
        "    pass\n",
        "  \n",
        "  def forward(self, x, predict=False):\n",
        "    # debes modificar tu implementación para que \n",
        "    # considere las probabilidades de dropout l_keep_prob\n",
        "    pass\n",
        "\n",
        "  def backward(x, y, y_pred):\n",
        "    # debes modificar tu implementación para que: \n",
        "    # - considere las probabilidades de dropout l_keep_prob\n",
        "    # - calcule el gradiente según l2_par\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjuRXBKjoAT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Acá agrega tu código para computar la pérdida con penalización, \n",
        "# lo puedes hacer mediante una funcion como en la tarea 2 o mediante \n",
        "# la definición de un nuevo módulo\n",
        "class RegLoss(nn.Module):\n",
        "  def __init__(self, parameters, l2_par=None):\n",
        "    pass\n",
        "  \n",
        "  def forward(Q, P):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGDf4Cd7Y913",
        "colab_type": "text"
      },
      "source": [
        "## 1b) Regularización por weight decay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2Ew7JdvbS_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Acá deberías modificar la implementación del optimizador SGD\n",
        "class SGD():\n",
        "  def __init__(self, parameters, lr, weight_decay=0):\n",
        "    # lo que sea necesario inicializar\n",
        "    pass\n",
        "  \n",
        "  # debes modificar el codigo de la Tarea 2\n",
        "  def step(self):\n",
        "    # actualiza acá los parámetros a partir de los gradientes\n",
        "    # y el weight_decay\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY3VZH1PcL5g",
        "colab_type": "text"
      },
      "source": [
        "#Parte 3: Entrenamiento y generalización sobre MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2A91Llafbwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Descarga y almacena el conjunto de train de MNIST.\n",
        "mnist_train_set = MNIST('mnist', train=True, transform=ToTensor(), download=True)\n",
        "\n",
        "# Descarga y almacena el conjunto de test de MNIST.\n",
        "mnist_test_set = MNIST('mnist', train=False, transform=ToTensor(), download=True)\n",
        "\n",
        "print('Datos de train: {}, Datos de test: {}'.format(len(mnist_train_set), len(mnist_test_set)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOkIp2Q-iCQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Acá debes agregar tu código para entrenar usando el conjunto de \n",
        "# train (mnist_train_set) y probar usando el conjunto de test (mnist_test_set)\n",
        "# Debes entrenar sin usar regularización y con regularización\n",
        "# Modificar tu código de entrenar_FFNN para que retorne los \n",
        "# errores de entrenamiento y generalización"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZsDWICFiWL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Acá debes agregar tu código para mostrar las gráficas del error de \n",
        "# entrenamiento y generalización\n",
        "# Reporta al menos dos configuraciones que usen regularización"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9m6Qi72kYbJ",
        "colab_type": "text"
      },
      "source": [
        "**Acá debes discutir acerca de cómo varía la pérdida y el acierto en el conjunto de prueba comparado con cuando no usas regularización.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDD3QproIrSN",
        "colab_type": "text"
      },
      "source": [
        "# Parte 4 (Opcional): Aumento de datos sintéticamente\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_cVeviYIswM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Acá debes agregar tu código para hacer data augmentation sobre los \n",
        "# datos de entrenamiento de MNIST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7CO6B77laLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reporta cómo cambia el error de prueba y compáralo con no usar data augmentation."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}