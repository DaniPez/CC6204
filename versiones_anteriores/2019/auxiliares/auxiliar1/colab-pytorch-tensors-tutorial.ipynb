{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"colab-pytorch-tensors-tutorial.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"9YzoYSJzH6Ch","colab_type":"text"},"source":["# Colab\n","Google Colab es una herramienta de investigación para la enseñanza e investigación de Machine Learning. Es un entorno de **Jupyter notebook** que no requiere configuración para su uso. Colab ofrece un servicio gratuito de **GPU en la nube** alojado por Google para alentar la colaboración en el campo de Machine Learning, sin preocuparse por los requisitos de hardware. Colab fue lanzado al público por Google en octubre de 2017."]},{"cell_type":"markdown","metadata":{"id":"fDuk4lFegB8f","colab_type":"text"},"source":["## GPU\n","En Colab, obtendrá **12 horas de tiempo de ejecución**, pero la sesión se desconectará si está inactivo durante más de 60 minutos. Esto significa que por cada 12 horas, el disco, la RAM, la memoria caché de la CPU y los datos que se encuentran en nuestra máquina virtual asignada se **borrarán**.\n","\n","Para habilitar el uso del acelerador de hardware GPU, solo es necesario ir a **Runtime -> Change runtime type -> Hardware accelerator -> GPU**"]},{"cell_type":"code","metadata":{"id":"tqASP2gcrZsf","colab_type":"code","outputId":"a144af4d-8508-4056-ef5d-7fe0ba3bbd04","executionInfo":{"status":"ok","timestamp":1565727616184,"user_tz":240,"elapsed":2097,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["!nvidia-smi"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Tue Aug 13 20:20:15 2019       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   47C    P8    15W /  70W |      0MiB / 15079MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5eytPOlerYV2","colab_type":"code","outputId":"dacfe7ae-82d2-45be-cf96-9c62e205e74a","executionInfo":{"status":"ok","timestamp":1565727710144,"user_tz":240,"elapsed":3165,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["!nvidia-smi --query-gpu=memory.total,memory.used,memory.free --format=csv"],"execution_count":0,"outputs":[{"output_type":"stream","text":["memory.total [MiB], memory.used [MiB], memory.free [MiB]\n","15079 MiB, 0 MiB, 15079 MiB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"buIf0fcvrpi-","colab_type":"text"},"source":["## RAM"]},{"cell_type":"code","metadata":{"id":"gwroe-mPr5JN","colab_type":"code","outputId":"57d669a0-1378-4028-bb8a-18620fb0b510","executionInfo":{"status":"ok","timestamp":1565727795410,"user_tz":240,"elapsed":2098,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["!free -h"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              total        used        free      shared  buff/cache   available\n","Mem:            12G        403M         10G        920K        1.9G         12G\n","Swap:            0B          0B          0B\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Jny2zyWixPVT","colab_type":"text"},"source":["## Almacenamiento"]},{"cell_type":"code","metadata":{"id":"XOw2r_iYsDEN","colab_type":"code","outputId":"8f9beb70-f026-4756-f69d-64383bd645fb","executionInfo":{"status":"ok","timestamp":1565727812590,"user_tz":240,"elapsed":4843,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["!df -h --total | grep Filesystem\n","!df -h --total | grep total"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Filesystem      Size  Used Avail Use% Mounted on\n","total           755G   69G  668G  10% -\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KA-31YkdgJ3E","colab_type":"text"},"source":["## Google Drive"]},{"cell_type":"code","metadata":{"id":"8GqpXS-ggNoP","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cEKNHqJcxjvl","colab_type":"text"},"source":["## Clonando repo"]},{"cell_type":"code","metadata":{"id":"DBH4OrsoxnNi","colab_type":"code","outputId":"fd3f330a-2755-4f11-83d0-c21a2b4ce42f","executionInfo":{"status":"ok","timestamp":1565890630391,"user_tz":240,"elapsed":5172,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["import os\n","\n","if not os.path.exists('/content/cc6204-DeepLearning-DCCUChile'):\n","  !git clone https://github.com/jorgeperezrojas/cc6204-DeepLearning-DCCUChile.git"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'cc6204-DeepLearning-DCCUChile'...\n","remote: Enumerating objects: 11, done.\u001b[K\n","remote: Counting objects:   9% (1/11)\u001b[K\rremote: Counting objects:  18% (2/11)\u001b[K\rremote: Counting objects:  27% (3/11)\u001b[K\rremote: Counting objects:  36% (4/11)\u001b[K\rremote: Counting objects:  45% (5/11)\u001b[K\rremote: Counting objects:  54% (6/11)\u001b[K\rremote: Counting objects:  63% (7/11)\u001b[K\rremote: Counting objects:  72% (8/11)\u001b[K\rremote: Counting objects:  81% (9/11)\u001b[K\rremote: Counting objects:  90% (10/11)\u001b[K\rremote: Counting objects: 100% (11/11)\u001b[K\rremote: Counting objects: 100% (11/11), done.\u001b[K\n","remote: Compressing objects: 100% (9/9), done.\u001b[K\n","remote: Total 5693 (delta 0), reused 11 (delta 0), pack-reused 5682\u001b[K\n","Receiving objects: 100% (5693/5693), 7.19 MiB | 10.23 MiB/s, done.\n","Resolving deltas: 100% (2740/2740), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VBrmK3h0zoLL","colab_type":"code","outputId":"fe038739-4ee4-4b30-8b47-498dbed64d9a","executionInfo":{"status":"ok","timestamp":1565727912327,"user_tz":240,"elapsed":1795,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cc6204-DeepLearning-DCCUChile  sample_data\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6NJKA-RsKDaz","colab_type":"text"},"source":["# Pytorch\n","Provee 2 caracteristicas fundamentales:\n","1. n-dimensional Tensor, similar a Numpy pero pueden almacenarce en GPUs\n","2. diferenciación automática para el entrenamiento de Redes Neuronales\n","\n","## Instalación\n","Pytorch se encuentra instalado en la máquina virtual de Colab. Pero si desea correr este notebook en otro entorno, puede que necesite instalarlo. En https://pytorch.org/ puede encontrar una guía completa.\n"]},{"cell_type":"code","metadata":{"id":"cCJrdKoGX1P3","colab_type":"code","colab":{}},"source":["# uncomment if you need to install last version of torch with CUDA\n","#!pip3 install torch torchvision\n","\n","# uncomment if you need to install last version of torch without CUDA\n","#!pip3 install torch==1.2.0+cpu torchvision==0.4.0+cpu -f https://download.pytorch.org/whl/torch_stable.html"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"88BjGz5La6Ba","colab_type":"text"},"source":["## Importar PyTorch y otros paquetes\n","Primero, importaremos las bibliotecas requeridas. Recuerde que torch, numpy y matplotlib están preinstalados en la máquina virtual de Colab."]},{"cell_type":"code","metadata":{"id":"yjMNP3R_a4f1","colab_type":"code","colab":{}},"source":["import torch\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gyJk3XsDFl62","colab_type":"code","outputId":"0dd4e54c-1402-409f-f245-3f9c22c9111e","executionInfo":{"status":"ok","timestamp":1565728193423,"user_tz":240,"elapsed":638,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["torch.__version__"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.1.0'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"FDGbpn2gXOQe","colab_type":"text"},"source":["## Tensor\n","Las operaciones basadas en Numpy no están optimizadas para utilizar GPU y acelerar sus cálculos numéricos. Para las redes neuronales profundas modernas, las GPU a menudo proporcionan aceleraciones de 50x o más. Entonces, desafortunadamente, numpy no será suficiente para el aprendizaje profundo moderno. Aquí es donde Pytorch introduce el concepto de Tensor. Un tensor de Pytorch es conceptualmente idéntico a una matriz numpy n-dimensional. Con la diferencia de que los tensores de PyTorch pueden utilizar GPU para acelerar sus cálculos numéricos."]},{"cell_type":"markdown","metadata":{"id":"mjYL5YAeMZsN","colab_type":"text"},"source":["En PyTorch el tipo de tensor predeterminado es **float** definido como **torch.FloatTensor**. Podemos crear tensores utilizando las **funciones incorporadas** dentro del paquete."]},{"cell_type":"code","metadata":{"id":"-mE64px7NZ1s","colab_type":"code","outputId":"7fa7562f-bf9d-44cc-e29d-5e73024c52cc","executionInfo":{"status":"ok","timestamp":1565728319311,"user_tz":240,"elapsed":846,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["## creating a tensor of 3 rows and 2 columns consisting of ones\n","a = torch.ones(3,2)\n","\n","## creating a tensor of 3 rows and 2 columns consisting of zeros\n","b = torch.zeros(3,2)\n","\n","print('a=\\n{}'.format(a))\n","print('b=\\n{}'.format(b))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["a=\n","tensor([[1., 1.],\n","        [1., 1.],\n","        [1., 1.]])\n","b=\n","tensor([[0., 0.],\n","        [0., 0.],\n","        [0., 0.]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gJiuUxVOcEs5","colab_type":"text"},"source":["Podemos crear los tensores **a partir de listas de Python o sequencias** mediante el constructor `torch.tensor()`"]},{"cell_type":"code","metadata":{"id":"0kRqKUuXczyA","colab_type":"code","outputId":"0d4b1ffd-9ddf-4a91-b83b-90fa29606d16","executionInfo":{"status":"ok","timestamp":1565728355194,"user_tz":240,"elapsed":2131,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["a = torch.tensor([[1., -1.], [-1., 1.]])\n","b = torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))\n","\n","print('a=\\n{}'.format(a))\n","print('b=\\n{}'.format(b))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["a=\n","tensor([[ 1., -1.],\n","        [-1.,  1.]])\n","b=\n","tensor([[1, 2, 3],\n","        [4, 5, 6]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4do0hVbvN4FP","colab_type":"text"},"source":["Inicialización **aleatoria**"]},{"cell_type":"code","metadata":{"id":"rsvHPhhnOEIz","colab_type":"code","outputId":"5ca60c79-3a03-4d27-ccf4-972214bd246d","executionInfo":{"status":"ok","timestamp":1565728481753,"user_tz":240,"elapsed":1073,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["#to increase the reproducibility, we often set the random seed to a specific value first.\n","torch.manual_seed(2)\n","\n","#generating tensor randomly from uniform distribution on the interval [0, 1)\n","a = torch.rand(3, 2) \n","\n","#generating tensor randomly from standar normal distribution (mean 0 and variance 1)\n","b = torch.randn(3, 3)\n","\n","print('a=\\n{}'.format(a))\n","print('b=\\n{}'.format(b))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["a=\n","tensor([[0.6147, 0.3810],\n","        [0.6371, 0.4745],\n","        [0.7136, 0.6190]])\n","b=\n","tensor([[-2.1409, -0.5534, -0.5000],\n","        [-0.0815, -0.1633,  1.5277],\n","        [-0.4023,  0.0972, -0.5682]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"U-y-wmGKUQsa","colab_type":"text"},"source":["## PyTorch <--> numpy\n","Convertir un tensor de PyTorch a `ndarray` de numpy puede ser conveniente algunas veces. Mediante el uso de `.numpy()` sobre un tensor podemos convertir facilmente el tensor a `ndarray`."]},{"cell_type":"code","metadata":{"id":"71OB_OVdU44w","colab_type":"code","outputId":"7b34ba40-cf21-46c2-fcee-46dca3eb5575","executionInfo":{"status":"ok","timestamp":1565728583993,"user_tz":240,"elapsed":637,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["x = torch.linspace(0, 1, steps = 5)  # creating a tensor using linspace\n","print(x)\n","x_np = x.numpy()  # convert tensor to numpy\n","print(type(x), type(x_np))  # check the types "],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n","<class 'torch.Tensor'> <class 'numpy.ndarray'>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"S7u8IYkyVUuY","colab_type":"text"},"source":["Para convertir de `ndarray` a `tensor`, podemos usar `.from_numpy()`"]},{"cell_type":"code","metadata":{"id":"NZHwbeG0Vqin","colab_type":"code","outputId":"0b00ffa0-2cfd-424d-d648-631753098f78","executionInfo":{"status":"ok","timestamp":1565728602095,"user_tz":240,"elapsed":881,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["x = np.random.randn(5)  # generate a random numpy array\n","print(x)\n","x_pt = torch.from_numpy(x)  # convert numpy array to a tensor\n","print(type(x), type(x_pt)) "],"execution_count":0,"outputs":[{"output_type":"stream","text":["[-0.87881851 -0.61338628  0.66181552  0.92286251 -1.3474736 ]\n","<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LFlM-1x2WCEs","colab_type":"text"},"source":["## CUDA\n","Para verificar cuántas GPU compatibles con CUDA están conectadas a la máquina, puede usar el fragmento de código a continuación. Si está ejecutando el código en Colab obtendrá `1`, eso significa que la máquina virtual Colab está conectada a una GPU. `torch.cuda` se usa para configurar y ejecutar operaciones CUDA."]},{"cell_type":"code","metadata":{"id":"oztGCyHUWihQ","colab_type":"code","outputId":"0b54c843-60b8-4e7f-f58a-a7846d2ae877","executionInfo":{"status":"ok","timestamp":1565728646702,"user_tz":240,"elapsed":955,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["if torch.cuda.is_available():\n","  print(torch.cuda.device_count())\n","  print(torch.cuda.get_device_name(0))  # name of the first GPU Card connected to the machine"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1\n","Tesla T4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"koUFk8piXe-N","colab_type":"text"},"source":["Lo importante a tener en cuenta es que podemos referenciar esta tarjeta GPU compatible con CUDA desde una variable y usarla para cualquier operación de Pytorch. Todos los tensores CUDA que asigne se crearán en ese dispositivo. El dispositivo GPU seleccionado se puede cambiar con un administrador de contexto `torch.cuda.device`."]},{"cell_type":"code","metadata":{"id":"rG5bHphZXOh7","colab_type":"code","outputId":"20d77d05-cbc0-48f4-cb00-d9c30793c83f","executionInfo":{"status":"ok","timestamp":1565728752973,"user_tz":240,"elapsed":7885,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# Assign cuda GPU located at location '0' to a variable\n","cuda0 = torch.device('cuda:0')\n","\n","# Performing the addition on GPU\n","a = torch.ones(3, 2, device=cuda0)  # creating a tensor 'a' on GPU 0\n","b = torch.ones(3, 2, device=cuda0)  # creating a tensor 'b' on GPU 0\n","# b = torch.ones(3, 2)  # creating a tensor 'b' on GPU 0\n","c = a + b + 5\n","print(c)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[7., 7.],\n","        [7., 7.],\n","        [7., 7.]], device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9xPPL2ErYpsl","colab_type":"text"},"source":["Si desea mover el resultado a la CPU, solo tiene que hacer `.cpu()`"]},{"cell_type":"code","metadata":{"id":"msmpvAERYtu_","colab_type":"code","outputId":"c8bad869-25f0-45ae-86fd-0caa5096c06d","executionInfo":{"status":"ok","timestamp":1565728812226,"user_tz":240,"elapsed":680,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["c = c.cpu()\n","print(c)\n","c = c.cuda()\n","print(c)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[7., 7.],\n","        [7., 7.],\n","        [7., 7.]])\n","tensor([[7., 7.],\n","        [7., 7.],\n","        [7., 7.]], device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ObMriFD3sn-I","colab_type":"text"},"source":["### Checkeando tiempo de computo"]},{"cell_type":"code","metadata":{"id":"xEHtjCOZswRe","colab_type":"code","outputId":"ccbe89f4-7fa5-47e8-8031-389f0d743d64","executionInfo":{"status":"ok","timestamp":1565728900020,"user_tz":240,"elapsed":32007,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["import time\n","\n","size_matrix = 10000\n","x = torch.randn((size_matrix, size_matrix))\n","y = torch.randn((size_matrix, size_matrix))\n","\n","# CPU\n","print('mm in CPU...')\n","start = time.clock()\n","z = torch.mm(x,y)\n","total_time = time.clock() - start\n","print('CPU time = {}'.format(total_time))\n","\n","# GPU\n","print('mm in GPU...')\n","start = time.clock()\n","z = torch.mm(x.cuda(),y.cuda())\n","total_time = time.clock() - start\n","print('GPU time = {}'.format(total_time))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["mm in CPU...\n","CPU time = 26.897794000000005\n","mm in GPU...\n","GPU time = 0.17126500000000533\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mUajudUNOaue","colab_type":"text"},"source":["## Operaciones simples"]},{"cell_type":"markdown","metadata":{"id":"Xfn7N73SOok8","colab_type":"text"},"source":["### Slicing\n","Podemos hacer slice sobre los tensores de PyTorch de la misma forma que con los `ndarray`"]},{"cell_type":"code","metadata":{"id":"puWNqYX0OZqO","colab_type":"code","outputId":"18c80e0f-e50d-44bb-999b-1d97c1413e1a","executionInfo":{"status":"ok","timestamp":1565729110874,"user_tz":240,"elapsed":702,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# create a tensor\n","x = torch.tensor([[1, 2], \n","                 [3, 4], \n","                 [5, 6]])\n","\n","print(x[:, -1]) # every elements in dim 0, only last element in dim 1\n","print(x[0, :])  # only first elements in dim 0, every elements in dim 1\n","print(x[1, 1])  # take the 2nd element in dim 0 and 2nd element in dim 1. Create another tensor"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([2, 4, 6])\n","tensor([1, 2])\n","tensor(4)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bDJU8tI3QC8h","colab_type":"text"},"source":["### Reshape \n","Cambiar el shape de un tensor"]},{"cell_type":"code","metadata":{"id":"KFfJoiWOQTcK","colab_type":"code","outputId":"bd7814a8-7368-4762-d749-c156da6d66a9","executionInfo":{"status":"ok","timestamp":1565729263899,"user_tz":240,"elapsed":770,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["# get size of tensor\n","x_size = x.size()\n","print('size of x: {}'.format(x_size))\n","\n","x_dim1 = x.size(1)\n","print('size of dim 1: {}'.format(x_dim1))\n","\n","# reshape\n","y = x.view(2, 3)\n","print('y=\\n{}'.format(y))\n","\n","# transpose\n","y = x.transpose(0, 1)\n","print('y=\\n{}'.format(y))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["size of x: torch.Size([3, 2])\n","size of dim 1: 2\n","y=\n","tensor([[1, 2, 3],\n","        [4, 5, 6]])\n","y=\n","tensor([[1, 3, 5],\n","        [2, 4, 6]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sXJH-4QXQri6","colab_type":"text"},"source":["#### Uso de `-1` al redimensionar los tensores\n","`-1` indica que la dimension se deducirá de las dimensiones anteriores. En el fragmento de código a continuación `x.view(-1, 18)` dará como resultado un tensor de forma 2x18 porque hemos establecido el tamaño de la segunda dimensión a 18. Pytorch **inferirá el tamaño** de la primera dimiensión de modo que sea capaz de acomodar todos los valores presentes en el tensor.\n"]},{"cell_type":"code","metadata":{"id":"7p-s7ICZRZGo","colab_type":"code","outputId":"a0903d76-bf38-4b85-82d0-6ae7991213fe","executionInfo":{"status":"ok","timestamp":1565729404976,"user_tz":240,"elapsed":642,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["x = torch.randn(6, 6)\n","y1 = x.view(-1, 18)\n","y2 = x.view(2, 6, -1)\n","# y2 = x.view(2, 5, -1)  # Error because shape '[2, 5, -1]' is invalid for input of size 36\n","\n","print(\"x = \\n{}\".format(x))\n","print(\"y1 =\\n{}\".format(y1.size()))\n","print(\"y2 =\\n{}\".format(y2.size()))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["x = \n","tensor([[ 1.1842, -0.2227, -0.7212, -0.3555, -1.3593, -0.0171],\n","        [ 1.5292,  0.9322, -0.6437,  0.3107,  1.3783, -2.0232],\n","        [ 0.1904, -1.0397,  0.2672, -0.1197,  1.1307, -0.3734],\n","        [ 1.0807, -1.1145,  1.0233,  0.1579,  0.2713, -1.3069],\n","        [ 0.8160, -2.2577,  0.8149,  0.0805,  0.9032,  0.7585],\n","        [ 1.2038, -1.6814, -0.8208,  0.0831, -0.1917, -0.9243]])\n","y1 =\n","torch.Size([2, 18])\n","y2 =\n","torch.Size([2, 6, 3])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z65p9v5pSq7E","colab_type":"text"},"source":["## Operaciones\n"]},{"cell_type":"code","metadata":{"id":"3OVlkr7mS4iu","colab_type":"code","outputId":"c8924535-1e22-4876-c890-a0218dedb215","executionInfo":{"status":"ok","timestamp":1565729579945,"user_tz":240,"elapsed":1872,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["# create three tensors\n","x = torch.ones(3, 2)\n","y = torch.ones(3, 2)\n","\n","# Pytorch does not allow any type of computation between different types of data\n","# y1 = torch.LongTensor(3, 2)\n","# print(x.dtype, y1.dtype)\n","# z = x + y1  # error\n","\n","# change the type of tensor\n","# y1 = y1.type(torch.FloatTensor)\n","# print(x.dtype, y1.dtype)\n","# z = x + y1  # correct\n","\n","# adding two tensors (element-wise)\n","z1 = x + y            # method 1\n","z2 = torch.add(x, y)  # method 2\n","print('add=\\n{}'.format(z1), 'ok' if torch.all(z1 == z2) else 'wrong')\n","\n","# subtracting two tensors (element-wise)\n","z1 = x - y            # method 1\n","z2 = torch.sub(x, y)  # method 2\n","print('sub=\\n{}'.format(z1), 'ok' if torch.all(z1 == z2) else 'wrong')\n","\n","# multiplying two tensors (element-wise)\n","z1 = (x + 1) * (y + 2)        # method 1\n","z2 = torch.mul(x + 1, y + 2)  # method 2\n","print('mul=\\n{}'.format(z1), 'ok' if torch.all(z1 == z2) else 'wrong')\n","\n","# matrix multiplication\n","z1 = x @ y.view(2, 3)           # method 1\n","z2 = torch.mm(x, y.view(2, 3))  # method 2\n","print('mm=\\n{}'.format(z1), 'ok' if torch.all(z1 == z2) else 'wrong')\n","\n","# dot product, the result is a scalar\n","z1 = torch.Tensor([4, 2]) @ torch.Tensor([3, 1])           # method 1\n","z2 = torch.dot(torch.Tensor([4, 2]), torch.Tensor([3, 1])) # method 2\n","print('dot= {}'.format(z1), 'ok' if torch.all(z1 == z2) else 'wrong')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["add=\n","tensor([[2., 2.],\n","        [2., 2.],\n","        [2., 2.]]) ok\n","sub=\n","tensor([[0., 0.],\n","        [0., 0.],\n","        [0., 0.]]) ok\n","mul=\n","tensor([[6., 6.],\n","        [6., 6.],\n","        [6., 6.]]) ok\n","mm=\n","tensor([[2., 2., 2.],\n","        [2., 2., 2.],\n","        [2., 2., 2.]]) ok\n","dot= 14.0 ok\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6CBbqcuGTMUy","colab_type":"text"},"source":["### Inplace\n","En Pytorch, todas las operaciones en el tensor que operan in-place tendrán un `_` como posfijo. Por ejemplo, `add` es la versión out-of-place y `add_` es la versión in-place."]},{"cell_type":"code","metadata":{"id":"mDP2hZgOTOaZ","colab_type":"code","outputId":"384cc3d2-4e8f-49a5-df5c-345fe4e6efee","executionInfo":{"status":"ok","timestamp":1565729666355,"user_tz":240,"elapsed":682,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["y.add_(x)  # tensor y added with x and result will be stored in y"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[2., 2.],\n","        [2., 2.],\n","        [2., 2.]])"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"c-UNJsgVotXa","colab_type":"text"},"source":["## Broadcasting en PyTorch"]},{"cell_type":"markdown","metadata":{"id":"GT3dAnGjpJxf","colab_type":"text"},"source":["Muchas operaciones en PyTorch soportan [NumPy Broadcasting Semantics](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html#module-numpy.doc.broadcasting).\n","\n","Si una operación PyTorch admite la broadcast, sus argumentos (tensores) se pueden expandir automáticamente para que sean del mismo tamaño (**sin hacer copias de los datos**). *No es más que una forma de hacer operaciones punto a punto sobre tensores que no necesariamente tienen las mismas dimensiones.*\n","\n","Dos tensores son \"broadcastable\" si:\n","1. Cada tensor tiene al menos una dimensión.\n","2. Al iterar sobre los tamaños de las dimensiones (comenzando en la dimensión final), sus tamaños deben ser iguales, uno de ellos es `1` o uno de ellos no existe.\n","\n","Si dos tensores son \"broadcastable\" las dimensiones del tensor resultado se determina mediante:\n","1. Si el número de dimensiones no es igual, se antepone `1` a las dimensiones del tensor con menos dimensiones para que tengan la misma longitud.\n","2. Luego, para cada tamaño de dimensión, el tamaño de dimensión resultante es el máximo de los tamaños en esa dimensión."]},{"cell_type":"code","metadata":{"id":"X6MX4Rvs2fby","colab_type":"code","outputId":"826e0794-e412-4606-f34e-4e7ec65d5b66","executionInfo":{"status":"error","timestamp":1565730240086,"user_tz":240,"elapsed":757,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":299}},"source":["x = torch.rand(3)\n","z = x + 4  # sum the scalar to each element\n","print('z= {}'.format(z))\n","\n","x = torch.randn(5,7,3)\n","y = torch.randn(5,7,3)\n","z = x + y  # same shapes are always broadcastable\n","print('z= {}'.format(z.size()))\n","\n","x = torch.randn(5,3,4,1)\n","y = torch.randn(  3,1,1)\n","z = x + y\n","print('z= {}'.format(z.size()))\n","# x and y are broadcastable.\n","# 1st trailing dimension: both have size 1\n","# 2nd trailing dimension: y has size 1\n","# 3rd trailing dimension: x size == y size\n","# 4th trailing dimension: y dimension doesn't exist\n","\n","x = torch.rand(1,10)\n","y = torch.rand(10,1)\n","z = x + y\n","print('z= {}'.format(z.size()))\n","\n","# NOT broadcastables examples:\n","\n","# x = torch.randn(3,2)\n","# y = torch.randn(  3)\n","# z = x + y  # Error in the 1st trailing dimension 2 != 3\n","\n","# x = torch.empty((0,))\n","# y = torch.empty(2,2)\n","# z = x + y  # Error because x does not have at least 1 dimension\n","\n","# x=torch.empty(5,2,4,1)\n","# y=torch.empty(  3,1,1)\n","# z = x + y  # Error because in the 3rd trailing dimension 2 != 3"],"execution_count":0,"outputs":[{"output_type":"stream","text":["z= tensor([4.3393, 4.6648, 4.4774])\n","z= torch.Size([5, 7, 3])\n","z= torch.Size([5, 3, 4, 1])\n","z= torch.Size([10, 10])\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-3cdb062854c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m  \u001b[0;31m# Error in the 1st trailing dimension 2 != 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# x = torch.empty((0,))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1"]}]},{"cell_type":"markdown","metadata":{"id":"12s9Q3qS3zL7","colab_type":"text"},"source":["**Hay que tener cuidado**"]},{"cell_type":"markdown","metadata":{"id":"VKMMVk6GJ7OW","colab_type":"text"},"source":["## Definiendo los parámetros de la red"]},{"cell_type":"code","metadata":{"id":"qafEEhqwKE4x","colab_type":"code","outputId":"a480ccb3-c42e-490c-b0db-95d229355224","executionInfo":{"status":"ok","timestamp":1566262713639,"user_tz":240,"elapsed":848,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class MyModule(nn.Module):\n","    def __init__(self, in_size, h_size, out_size, levels):\n","        super(MyModule, self).__init__()\n","        self.__in = nn.Parameter(torch.rand(in_size, h_size))\n","        self.__hiddens = nn.ParameterList([nn.Parameter(torch.rand(h_size, h_size)) for i in range(levels)])\n","        self.__out = nn.Parameter(torch.rand(h_size, out_size))\n","\n","    def forward(self, x):\n","        h = x.mm(self.__in)\n","        \n","        # ParameterList can act as an iterable, or be indexed using ints\n","        for hidden in self.__hiddens:\n","            h = h.mm(hidden)\n","      \n","        y = torch.sigmoid(h.mm(self.__out))\n","        return y\n","      \n","net = MyModule(in_size=128, h_size=200, out_size=1, levels=5)\n","print(net)\n","print('Count of parameters: {}'.format(len(list(net.parameters()))))\n","\n","x = torch.ones(1, 128)\n","print(net(x))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["MyModule(\n","  (_MyModule__hiddens): ParameterList(\n","      (0): Parameter containing: [torch.FloatTensor of size 200x200]\n","      (1): Parameter containing: [torch.FloatTensor of size 200x200]\n","      (2): Parameter containing: [torch.FloatTensor of size 200x200]\n","      (3): Parameter containing: [torch.FloatTensor of size 200x200]\n","      (4): Parameter containing: [torch.FloatTensor of size 200x200]\n","  )\n",")\n","Count of parameters: 7\n","tensor([[1.]], grad_fn=<SigmoidBackward>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BEOxYob8RKzQ","colab_type":"text"},"source":["## Dataset, DataLoader y btachs\n","`Dataset` es una clase abstracta que representa un conjunto de datos.\n","\n","Todos los conjuntos de datos que representan un mapa de key->target deben ser subclases de `Dataset`. Todas las subclases deben sobrescribir `__getitem__()`, lo que permite recuperar una muestra de datos para un k determinado. Las subclases también podrían sobrescribir opcionalmente `__len__()`, que se espera que devuelva el tamaño del conjunto de datos."]},{"cell_type":"code","metadata":{"id":"yPSLSStsSoze","colab_type":"code","outputId":"d8f83ecd-022b-4398-bef0-2c25a5c2444d","executionInfo":{"status":"ok","timestamp":1565731044546,"user_tz":240,"elapsed":853,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["import torch.utils.data as data\n","\n","class MyDataset(data.Dataset):\n","  def __init__(self, vectors, targets):\n","    self.vectors = vectors\n","    self.targets = targets\n","    \n","  def __getitem__(self, index):\n","    return vectors[index], targets[index]\n","  \n","  def __len__(self):\n","    return len(vectors)\n","\n","# generate random data\n","import random\n","odds = list(range(0, 10000, 2))\n","evens = list(range(1, 10000, 2))\n","vectors = [torch.FloatTensor([random.sample(odds if i%2==0 else evens, 128)]) for i in range(1000)]\n","targets = [i%2==0 for i in range(1000)]\n","\n","# create Dataset\n","dataset = MyDataset(vectors, targets)\n","\n","# define data loader by batchs\n","loader = data.DataLoader(dataset, batch_size=100, shuffle=True)\n","\n","# define net model\n","net = MyModule(128, 200, 1, 2)\n","\n","# itering over batchs\n","for i, (x, y) in enumerate(loader):\n","  # (batch_size x 1 x 128) -> (batch_size x 128)\n","  x = x.view(-1, 128)\n","  \n","  # compute predictions\n","  prediction = net(x)\n","  \n","  print('iter {}: {}'.format(i, prediction.size()))\n","  \n","  # here you are going to compute accuracy, loss and update weights\n","  # ..."],"execution_count":0,"outputs":[{"output_type":"stream","text":["iter 0: torch.Size([100, 1])\n","iter 1: torch.Size([100, 1])\n","iter 2: torch.Size([100, 1])\n","iter 3: torch.Size([100, 1])\n","iter 4: torch.Size([100, 1])\n","iter 5: torch.Size([100, 1])\n","iter 6: torch.Size([100, 1])\n","iter 7: torch.Size([100, 1])\n","iter 8: torch.Size([100, 1])\n","iter 9: torch.Size([100, 1])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zNf9VQ5blUlf","colab_type":"text"},"source":["## Diferenciación\n","La función de activación Leaky rectified linear unit (Leaky ReLU) se define como :\n","\n","$$ f(x) =\n","\\left\\{\n","\t\\begin{array}{ll}\n","\t\tx  & \\mbox{if } x \\geq 0 \\\\\n","\t\t\\alpha \\cdot x & \\mbox{if } x < 0\n","\t\\end{array}\n","\\right. \n","$$\n","\n","Por lo tanto su derivada será:\n","$$ \\frac{d\\,f}{dx}(x) =\n","\\left\\{\n","\t\\begin{array}{ll}\n","\t\t1  & \\mbox{if } x \\geq 0 \\\\\n","\t\t\\alpha & \\mbox{if } x < 0\n","\t\\end{array}\n","\\right. \n","$$"]},{"cell_type":"code","metadata":{"id":"mHfQg1_DlTll","colab_type":"code","outputId":"3919dc13-9d04-47e8-d8e9-96c392611b53","executionInfo":{"status":"ok","timestamp":1565731277162,"user_tz":240,"elapsed":864,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["def leaky_relu(x, alpha, gradient = False):\n","  if gradient:\n","    y = torch.ones_like(x)\n","    y[x < 0]  = alpha\n","    return y\n","  \n","  y = x\n","  y[y < 0] = alpha * y[y < 0]\n","  \n","  return y\n","\n","x = torch.randn(1,5)\n","print(\"x = {}\".format(x))\n","\n","leaky_relu = leaky_relu(x, 0.1, gradient=True)\n","print(\"leaky_relu(x, 0.1) = {}\".format(leaky_relu))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["x = tensor([[-0.7398, -0.1336, -1.9105, -0.9299,  0.5905]])\n","leaky_relu(x, 0.1) = tensor([[0.1000, 0.1000, 0.1000, 0.1000, 1.0000]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NmmwPcVfY73a","colab_type":"text"},"source":["## Diferenciación automática\n","El paquete `autograd` nos brinda la capacidad de realizar diferenciación automática o cálculo automático de gradiente para todas las operaciones en tensores. Es un define-by-run framework, lo que significa que nuestro back-propagation queda definido por cómo se ejecuta nuestro código.\n","\n","Veamos cómo realizar una diferenciación automática mediante un ejemplo simple. Primero, creamos un tensor con el parámetro `require_grad` establecido en `True` porque queremos rastrear todas las operaciones que se realizan en ese tensor."]},{"cell_type":"code","metadata":{"id":"pKyIDCnDZ4Ud","colab_type":"code","outputId":"506e960b-34fa-4c52-dca4-9bcfbb675e02","executionInfo":{"status":"ok","timestamp":1565731358474,"user_tz":240,"elapsed":694,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["# create a tensor with requires_grad = True\n","x = torch.ones([3,2], requires_grad=True)\n","print(x)\n","\n","# perform a simple tensor addition operation\n","y = x + 5  # tensor addition\n","print(y)  # check the result\n","\n","# perform more operations on y and create a new tensor z\n","z = y*y + 1\n","print(z)\n","\n","t = torch.sum(z)  # adding all the values in z\n","print(t)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[1., 1.],\n","        [1., 1.],\n","        [1., 1.]], requires_grad=True)\n","tensor([[6., 6.],\n","        [6., 6.],\n","        [6., 6.]], grad_fn=<AddBackward0>)\n","tensor([[37., 37.],\n","        [37., 37.],\n","        [37., 37.]], grad_fn=<AddBackward0>)\n","tensor(222., grad_fn=<SumBackward0>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EQF-jSXia3ju","colab_type":"text"},"source":["### Backpropagation"]},{"cell_type":"code","metadata":{"id":"0kgWeT1xbJYa","colab_type":"code","outputId":"55f07f0b-d9d1-49e5-fce1-8d0e91e43e49","executionInfo":{"status":"ok","timestamp":1565731455938,"user_tz":240,"elapsed":2681,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["t.backward() #peform backpropagation but pytorch will not print any output.\n","\n","# print gradients d(t)/dx\n","print(x.grad)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[12., 12.],\n","        [12., 12.],\n","        [12., 12.]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FFZ9dt82tXJe","colab_type":"text"},"source":["## SGD\n","El Descenso de Gradiente, o Descenso de Gradiente Estocástico, es un algoritmo de optimización para actualizar los parámetros del modelo de aprendizaje automático. Hay muchos otros algoritmos de actualización (a saber, optimizadores), pero SGD es más simple y fácil de implementar.\n","\n","Para este optimizador necesitamos una tasa de aprendizaje, generalmente un pequeño número flotante. Esta será una constante (al menos en SGD) que reflejará cuán abruptamente estaremos actualizando los parámetros de red. Cuanto más grande es, cuanto más cambiamos en cada iteración, más pequeño, más sutil es el cambio."]},{"cell_type":"code","metadata":{"id":"nhXtntXgtV6A","colab_type":"code","outputId":"a921b199-a99d-4b83-f09c-585791d89083","executionInfo":{"status":"ok","timestamp":1565731639165,"user_tz":240,"elapsed":781,"user":{"displayName":"Jesús Pérez","photoUrl":"","userId":"03422465056396107574"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["# Lets set the learning rate to 0.5\n","lr = 0.01\n","\n","# We generate 2 random tensors. One 1x2 and another 2x1\n","x = torch.randn(1,2, dtype=torch.float)\n","y = torch.randn(2,1)\n","\n","# we need to explicitly tell pytorch that we want this tensor to hace its gradients calculated\n","y.requires_grad_()\n","print(f\"Our tensor before the update:\\n {y}\")\n","\n","# Multiply the input tensor with our middle tensor\n","z = x @ y\n","print(\"\\nThe output: {}\".format(z))\n","\n","# calculate the gradients\n","z.backward()\n","\n","# this is just an indicator to pytorch to not listen to the following operations\n","# if we dont use this, the gradient could change unexpectedly\n","with torch.no_grad():\n","    y -= y.grad * lr  # update the tensor with the learning rate and its gradient\n","    y.grad.zero_()  # set the gradient to zero, we dont want this to accumulate\n","    \n","print(f\"\\nOur tensor after the update:\\n {y}\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Our tensor before the update:\n"," tensor([[ 1.8459],\n","        [-0.8448]], requires_grad=True)\n","\n","The output: tensor([[-5.2080]], grad_fn=<MmBackward>)\n","\n","Our tensor after the update:\n"," tensor([[ 1.8707],\n","        [-0.8523]], requires_grad=True)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sIz9sojhsXqL","colab_type":"text"},"source":["# Referencias\n","* Pytorch documentation: https://pytorch.org/docs/stable/index.html\n","* A tutorial on how autograd works: https://towardsdatascience.com/pytorch-autograd-understanding-the-heart-of-pytorchs-magic-2686cd94ec95"]}]}