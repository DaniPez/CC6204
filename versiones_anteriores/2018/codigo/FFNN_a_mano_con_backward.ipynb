{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FFNN_a_mano_v0.1_con_backward","version":"0.3.2","views":{},"default_view":{},"provenance":[{"file_id":"1JVNfrxNN8jpwjOszpwEegnKzvwDhGYWF","timestamp":1520378988084}],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"rr5EsNZxJhN8","colab_type":"text"},"cell_type":"markdown","source":["# CC6204 Deep Learning, Universidad de Chile\n","## Código de Red Neuronal \"casi a mano\", usando el `torch.autograd` \n","\n","El código está pensado para acompañar la clase de Back Propagation de CC6204 y servir como una introducción rápida a las funcionalidades básicas de pytorch, incluyendo autograd. No está pensado en ser un código modular, si no más bien un código pedagógico para los temas de grafo de computación, back propagation, y descenso de gradiente por paquetes. Es una versión usando autograd del código que aparece [acá](https://colab.research.google.com/drive/1LZ21iEeIX97kb_XEgv7bw-DQyITID_zm).\n","\n","(Pensado para correr en [Colaboratory](http://colab.research.google.com))\n","\n"]},{"metadata":{"id":"solFJy_c2iJN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# http://pytorch.org/\n","from os import path\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","\n","accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n","!pip install -q ipdb"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2JVQ13l32QpB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import torch\n","import numpy as np\n","import sys\n","import time\n","import ipdb\n","\n","# Genera una semilla fija para que los experimentos sea repetibles.\n","t_cg = torch.manual_seed(1547)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hDMZskhE2d1C","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Chequeamos si hay acceso a la GPU.\n","print(torch.cuda.is_available())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"U_EdIfcNA49D","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Funciones de activación:\n","\n","# Función sigmoid, recibe un objeto torch.Tensor\n","def sig(T):\n","  return torch.reciprocal(1 + torch.exp(-1 * T))\n","\n","# Función tanh, recibe un objeto torch.Tensor\n","def tanh(T):\n","  E = torch.exp(T)\n","  e = torch.exp(-1 * T)\n","  return (E - e) * torch.reciprocal(E + e)\n","\n","# Función de pérdida\n","def bi_cross_ent_loss(y_pred, y, safe=True, epsilon=1e-5):\n","  N = y.size()[0]\n","  \n","  if safe:\n","    # Asegura que no haya valores indefinidos.\n","    y_pred.data.clamp_(epsilon, 1-epsilon)\n","  \n","  B = (1-y) * torch.log(1-y_pred) + y * torch.log(y_pred)\n","  return -1/N * torch.sum(B)  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"SDWK7JHTbw7n","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Para elegir el siguiente batch (uno al azar) desde los datos de entrada\n","def elige_batch(X,Y,b):\n","  N = X.size()[0]\n","  x_lista = []\n","  y_lista = []\n","  \n","#  i = np.random.randint(N-b) # <-- descomentar esto para ejemplos\n","  for _ in range(b):\n","    i = np.random.randint(N) # <-- comentar esto para ejemplos\n","    x_lista.append(X[i:i+1])\n","    y_lista.append(Y[i:i+1])\n","  \n","  x = torch.cat(x_lista, dim=0)\n","  y = torch.cat(y_lista, dim=0)\n","  \n","  return x,y"],"execution_count":0,"outputs":[]},{"metadata":{"id":"I-nerXbn3X4z","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def ejemplo_FFNN(X, Y, b=1, d1=200, d2=300, lr=0.06, \n","                 epochs=10, run_in_GPU=True, reports_every=1, \n","                 cheq_grad=False, init_v=1):\n","  \n","  # Define un tipo para los tensores según si correrá en la GPU o no\n","  if run_in_GPU:\n","    assert torch.cuda.is_available()\n","    t_type = torch.cuda.FloatTensor\n","  else:\n","    t_type = torch.FloatTensor\n","    \n","  # Numero de ejemplos y cantidad de features\n","  N = X.size()[0]\n","  f = X.size()[1]\n","  \n","  # d0 es la cantidad de features  \n","  d0 = f\n","  \n","  # Crea los tensores de parámetros\n","  W1 = torch.randn(d0,d1).type(t_type) * init_v\n","  b1 = torch.zeros(d1).type(t_type)\n","  W2 = torch.randn(d1,d2).type(t_type) * init_v\n","  b2 = torch.zeros(d2).type(t_type)\n","  U = torch.randn(d2,1).type(t_type) * init_v\n","  c = torch.randn(1).type(t_type) \n","  \n","  ###############################\n","  # Convierte todo en variables\n","  W1 = torch.autograd.Variable(W1, requires_grad=True)\n","  b1 = torch.autograd.Variable(b1, requires_grad=True)\n","  W2 = torch.autograd.Variable(W2, requires_grad=True)\n","  b2 = torch.autograd.Variable(b2, requires_grad=True)\n","  U = torch.autograd.Variable(U, requires_grad=True)\n","  c = torch.autograd.Variable(c, requires_grad=True)\n","  ###############################\n","  \n","  parametros = {'W1':W1, 'b1':b1, 'W2':W2, 'b2':b2, 'U':U, 'c':c}\n","  \n","  # Cuenta los parámetros en total\n","  cant_parametros = 0\n","  for P in parametros:\n","    cant_parametros += parametros[P].nelement()      \n","  print('Cantidad de parámetros:', cant_parametros)\n","     \n","  tiempo_epochs = 0\n","  for e in range(1,epochs+1):  \n","    inicio_epoch = time.clock()\n"," \n","    # Cantidad de iteraciones por epoch (b es el tamaño del batch)\n","    I = int(N/b) \n","    \n","    for i in range(I):\n","      x, y = elige_batch(X,Y,b)\n","      # Asegura de pasarlos a la GPU si fuera necesario\n","      x = x.type(t_type)\n","      y = y.type(t_type)\n","      \n","      ###############################\n","      # Convierte en variables\n","      x = torch.autograd.Variable(x)\n","      y = torch.autograd.Variable(y)\n","      ###############################\n","      \n","      # Computa la pasada hacia adelante (forward)\n","      # No es necesario explicitar los calculos intermedios\n","      h1 = tanh(x.mm(W1).add(b1))\n","      h2 = sig(h1.mm(W2).add(b2))\n","      y_pred = sig(h2.mm(U).add(c))\n","                  \n","      # Computa la función de pérdida\n","      L = bi_cross_ent_loss(y_pred,y) \n","      \n","      ###############################\n","      # Todas las derivadas las puede\n","      # computar autograd\n","      L.backward()\n","      # Esta instrucción ejecuta el \n","      # backpropagation desde L\n","      ###############################\n","      \n","      # Actualiza los pesos\n","      for P in parametros:\n","        parametros[P].data -= lr * parametros[P].grad.data\n","        parametros[P].grad.data.zero_() \n","        # esto último lo necesitamos porque los gradientes\n","        # se acumulan en el backpropagation (ver clase de\n","        # backpropagation e implementación iterativa).\n","      \n","    tiempo_epochs += time.clock() - inicio_epoch\n","    \n","    if e % reports_every == 0:\n","      # Calcula la certeza de las predicciones sobre todo el conjunto\n","      X = X.type(t_type) # pasa a la GPU si fuera necesario\n","      Y = Y.type(t_type) # pasa a la GPU si fuera necesario\n","\n","      # Predice usando la red\n","      H1 = tanh(X.mm(W1.data).add(b1.data))\n","      H2 = sig(H1.mm(W2.data).add(b2.data))\n","      Y_PRED = sig(H2.mm(U.data).add(c.data))\n","      \n","      # Calcula la pérdida de todo el conjunto\n","      L_total = bi_cross_ent_loss(Y_PRED, Y, safe=False)\n","\n","      # Elige una clase dependiendo del valor de Y_PRED\n","      Y_PRED_BIN = (Y_PRED >= 0.5).float()\n","\n","      correctos = torch.sum(Y_PRED_BIN == Y)\n","      acc = correctos / N * 100\n","\n","      sys.stdout.write(\n","            '\\rEpoch:{0:03d}'.format(e) + ' Acc:{0:.2f}%'.format(acc)\n","            + ' Loss:{0:.4f}'.format(L_total) \n","            + ' Tiempo/epoch:{0:.3f}s'.format(tiempo_epochs/e)) \n","  \n","  return parametros"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uBBSkuxaEI7z","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["N = 5000 # numero de ejemplos\n","f = 300 # numero de features\n","\n","\n","X = torch.rand(N,f)\n","X = torch.bernoulli(X)\n","\n","Y = torch.rand(N,1)\n","Y = torch.bernoulli(Y)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XgaASdM0FnJ9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["epochs = 30\n","\n","red = ejemplo_FFNN(X, Y, b=32, d1=300, d2=200, epochs=epochs, \n","             run_in_GPU=True, lr=0.06, init_v=0.8)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Oluz-gTqF09b","colab_type":"text"},"cell_type":"markdown","source":["Para ejemplificar, probar el anterior código de la siguiente forma:\n","\n","*   Cambiar el tamaño del batch desde 2 a 1000: visualizar tiempo de entrenamiento vs Acc\n","*   Cambiar el tamaño de las capas / número de parámetros: visualizar tiempo de entrenamiento\n","*   Cambiar el valor máximo de inicialización (0.01,1,1.5,2)\n","*   Mostrar que se pueden calcular (aun) más eficiente la pasada hacia atrás reutilizando algunos valores previamente computados cuando derivamos `sig` y `tanh`: visualizar el tiempo de entrenamiento.\n","*   Descomentar la línea del generador de batches. ¿Cómo se explica el resultado?\n"]},{"metadata":{"id":"0yXpoazIcMp6","colab_type":"text"},"cell_type":"markdown","source":["Código por Jorge Pérez\n","\n","https://github.com/jorgeperezrojas\n","\n","@perez"]}]}